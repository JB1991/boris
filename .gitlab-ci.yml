image: docker:19

services:
  - docker:19-dind

stages:
  - init
  - test
  - build
  - package
  - deploy

cache: &global_cache
  key: ${CI_COMMIT_REF_SLUG}
  paths:
    - power/node_modules/
  policy: pull-push

install:
  stage: init
  image: node:lts-alpine
  needs: []
  dependencies: []
  cache:
    <<: *global_cache
  script:
    # install node modules
    - cd power
    - npm ci
    - node_modules/.bin/ngcc --tsconfig ./src/tsconfig.app.json -p es2015
  only:
    - merge_requests
    - tags
    - dev
    - staging
    - production

init:helm-dev:
  stage: init
  image: de.icr.io/lgln/kube-tools:latest
  needs: []
  dependencies: []
  cache: {}
  artifacts:
    name: "manifest"
    expire_in: 2 days
    paths:
      - manifest-dev
  script:
    - helm template power ./chart/power -f ./chart/power/values-dev.yaml --dependency-update --output-dir manifest-dev
  only:
    - merge_requests
    - tags
    - dev

init:helm-staging:
  stage: init
  image: de.icr.io/lgln/kube-tools:latest
  needs: []
  dependencies: []
  cache: {}
  artifacts:
    name: "manifest"
    expire_in: 2 days
    paths:
      - manifest-staging
  script:
    - helm template power ./chart/power -f ./chart/power/values-staging.yaml --dependency-update --output-dir manifest-staging
  only:
    - staging

init:helm-production:
  stage: init
  image: de.icr.io/lgln/kube-tools:latest
  needs: []
  dependencies: []
  cache: {}
  artifacts:
    name: "manifest"
    expire_in: 2 days
    paths:
      - manifest-production
  script:
    - helm template power ./chart/power -f ./chart/power/values-production.yaml --dependency-update --output-dir manifest-production
  only:
    - production

test:karma:
  stage: test
  image: trion/ng-cli-karma:latest
  needs: ["install"]
  dependencies: []
  cache:
    <<: *global_cache
    policy: pull
  artifacts:
    expire_in: 2 weeks
    reports:
      junit: power/output/junit_karma.xml
    paths:
      - power/output/junit_karma.xml
  coverage: '/Lines \W+: (\d+\.\d+)%.*/'
  script:
    # Run Karma tests
    - cd power
    - node_modules/@angular/cli/bin/ng test --browsers ChromeHeadlessNoSandbox --progress false --watch false --code-coverage
  only:
    - merge_requests
    - tags
    - dev
    - staging
    - production

test:e2e:
  stage: test
  image: trion/ng-cli-e2e:latest
  needs: ["install"]
  dependencies: []
  cache:
    <<: *global_cache
    policy: pull
  artifacts:
    expire_in: 2 weeks
    reports:
      junit: power/output/junit_e2e.xml
    paths:
      - power/output/junit_e2e.xml
  script:
    # Run E2E tests
    - cd power
    - node_modules/@angular/cli/bin/ng e2e --protractor-config e2e/protractor-ci.conf.js
  only:
    - merge_requests
    - tags
    - dev
    - staging
    - production
  when: manual

test:audit:
  stage: test
  image: node:lts-alpine
  needs: []
  dependencies: []
  cache: {}
  script:
    - cd power
    - npm audit
  only:
    - merge_requests
    - tags
    - dev
    - staging
    - production
  allow_failure: true

test:lint:
  stage: test
  image: node:lts-alpine
  needs: ["install"]
  dependencies: []
  cache:
    <<: *global_cache
    policy: pull
  script:
    - cd power
    - node_modules/@angular/cli/bin/ng lint power
  only:
    - merge_requests
    - tags
    - dev
    - staging
    - production

test:lint-html:
  stage: test
  image: node:lts-alpine
  needs: ["install"]
  dependencies: []
  cache:
    <<: *global_cache
    policy: pull
  script:
    - cd power
    - npm run lint:html
  only:
    - merge_requests
    - tags
    - dev
    - staging
    - production

test:lint-styles:
  stage: test
  image: node:lts-alpine
  needs: ["install"]
  dependencies: []
  cache:
    <<: *global_cache
    policy: pull
  script:
    - cd power
    - npm run lint:styles
  only:
    - merge_requests
    - tags
    - dev
    - staging
    - production

test:helm-dry-run:
  stage: test
  image: de.icr.io/lgln/kube-tools:latest
  needs: []
  dependencies: []
  cache: {}
  script:
    - kubectl config set-cluster k8s --server="$KUBE_API_URL" --insecure-skip-tls-verify=true
    - kubectl config set-credentials "$KUBE_DEPLOY_SECRET_NAME" --token="$KUBE_API_TOKEN"
    - kubectl config set-context default --cluster=k8s --user="$KUBE_DEPLOY_SECRET_NAME"
    - kubectl config use-context default
    - helm upgrade power ./chart/power -n dev -f ./chart/power/values-dev.yaml --install --set=image.tag="$CI_COMMIT_SHORT_SHA" --dry-run
  only:
    - dev
    - staging
    - production

test:kubesec-dev:
  stage: test
  image: de.icr.io/lgln/kube-tools:latest
  needs: ["init:helm-dev"]
  dependencies:
    - init:helm-dev
  cache: {}
  script:
    - cat manifest-dev/power/templates/*.yaml | kubesec-scan.sh -
    - cat manifest-dev/power/templates/*.yaml | kubesec-check.sh -
  only:
    - merge_requests
    - tags
    - dev

test:kubesec-staging:
  stage: test
  image: de.icr.io/lgln/kube-tools:latest
  needs: ["init:helm-staging"]
  dependencies:
    - init:helm-staging
  cache: {}
  script:
    - cat manifest-staging/power/templates/*.yaml | kubesec-scan.sh -
    - cat manifest-staging/power/templates/*.yaml | kubesec-check.sh -
  only:
    - staging

test:kubesec-production:
  stage: test
  image: de.icr.io/lgln/kube-tools:latest
  needs: ["init:helm-production"]
  dependencies:
    - init:helm-production
  cache: {}
  script:
    - cat manifest-production/power/templates/*.yaml | kubesec-scan.sh -
    - cat manifest-production/power/templates/*.yaml | kubesec-check.sh -
  only:
    - production

test:kube-linter-dev:
  stage: test
  image: de.icr.io/lgln/kube-tools:latest
  needs: ["init:helm-dev"]
  dependencies:
    - init:helm-dev
  cache: {}
  script:
    - kube-linter lint -v --add-all-built-in --exclude required-annotation-email,required-label-owner,default-service-account,run-as-non-root,no-read-only-root-fs manifest-dev/power/templates/*.yaml
  only:
    - merge_requests
    - tags
    - dev

test:kube-linter-staging:
  stage: test
  image: de.icr.io/lgln/kube-tools:latest
  needs: ["init:helm-staging"]
  dependencies:
    - init:helm-staging
  cache: {}
  script:
    - kube-linter lint -v --add-all-built-in --exclude required-annotation-email,required-label-owner,default-service-account,run-as-non-root,no-read-only-root-fs manifest-staging/power/templates/*.yaml
  only:
    - staging

test:kube-linter-production:
  stage: test
  image: de.icr.io/lgln/kube-tools:latest
  needs: ["init:helm-production"]
  dependencies:
    - init:helm-production
  cache: {}
  script:
    - kube-linter lint -v --add-all-built-in --exclude required-annotation-email,required-label-owner,default-service-account,run-as-non-root,no-read-only-root-fs manifest-production/power/templates/*.yaml
  only:
    - production

build:
  stage: build
  image: node:lts-alpine
  needs: ["install"]
  dependencies: []
  cache:
    <<: *global_cache
    policy: pull
  script:
    - cd power
    - npm run build -- -c staging
  artifacts:
    name: "compiled dist"
    expire_in: 2 days
    paths:
      - power/dist/power
  only:
    - merge_requests
    - tags
    - dev
    - staging

build:production:
  stage: build
  image: node:lts-alpine
  needs: ["install"]
  dependencies: []
  cache:
    <<: *global_cache
    policy: pull
  script:
    - cd power
    - npm run build -- --prod
  artifacts:
    name: "compiled dist"
    expire_in: 2 days
    paths:
      - power/dist/power
  only:
    - production

package:development:
  stage: package
  image: de.icr.io/lgln/kube-tools:latest
  dependencies:
    - build
  cache: {}
  script:
    - i=0; while [ "$i" -lt 12 ]; do docker info &> /dev/null && break; sleep 5; i=$(( i + 1 )) ; done
    - echo "$CI_REGISTRY_PASSWORD" | docker login --username "$CI_REGISTRY_USER" --password-stdin $CI_REGISTRY
    - docker build --pull -t "$CI_REGISTRY_IMAGE:latest" --build-arg=COMMIT="$CI_COMMIT_SHORT_SHA" --build-arg=BRANCH="$CI_COMMIT_REF_NAME" .
    - trivy image --no-progress --clear-cache --exit-code 1 "$CI_REGISTRY_IMAGE:latest"
    - docker push "$CI_REGISTRY_IMAGE:latest"
  only:
    - dev

package:staging:
  stage: package
  image: de.icr.io/lgln/kube-tools:latest
  dependencies:
    - build
  cache: {}
  environment: {
    name: staging
  }
  script:
    - i=0; while [ "$i" -lt 12 ]; do docker info &> /dev/null && break; sleep 5; i=$(( i + 1 )) ; done
    - echo "$CI_REGISTRY_PASSWORD" | docker login --username "$CI_REGISTRY_USER" --password-stdin $CI_REGISTRY
    - docker build --pull -t "$CI_REGISTRY_IMAGE:staging" --build-arg=COMMIT="$CI_COMMIT_SHORT_SHA" --build-arg=BRANCH="$CI_COMMIT_REF_NAME" .
    - trivy image --no-progress --clear-cache --exit-code 1 "$CI_REGISTRY_IMAGE:staging"
    - docker push "$CI_REGISTRY_IMAGE:staging"
  only:
    - staging

package:production:
  stage: package
  image: de.icr.io/lgln/kube-tools:latest
  dependencies:
    - build:production
  cache: {}
  environment: {
    name: production
  }
  script:
    - i=0; while [ "$i" -lt 12 ]; do docker info &> /dev/null && break; sleep 5; i=$(( i + 1 )) ; done
    - echo "$CI_REGISTRY_PASSWORD" | docker login --username "$CI_REGISTRY_USER" --password-stdin $CI_REGISTRY
    - docker build --pull -t "$CI_REGISTRY_IMAGE:production" --build-arg=COMMIT="$CI_COMMIT_SHORT_SHA" --build-arg=BRANCH="$CI_COMMIT_REF_NAME" .
    - trivy image --no-progress --clear-cache --exit-code 1 "$CI_REGISTRY_IMAGE:production"
    - docker push "$CI_REGISTRY_IMAGE:production"
  only:
    - production
  when: manual

deploy:development:
  stage: deploy
  image: de.icr.io/lgln/kube-tools:latest
  needs: ["package:development"]
  dependencies: []
  cache: {}
  script:
    - kubectl config set-cluster k8s --server="$KUBE_API_URL" --insecure-skip-tls-verify=true
    - kubectl config set-credentials "$KUBE_DEPLOY_SECRET_NAME" --token="$KUBE_API_TOKEN"
    - kubectl config set-context default --cluster=k8s --user="$KUBE_DEPLOY_SECRET_NAME"
    - kubectl config use-context default
    - helm upgrade power ./chart/power -n dev -f ./chart/power/values-dev.yaml --install
  only:
    - dev

deploy:staging:
  stage: deploy
  image: de.icr.io/lgln/kube-tools:latest
  needs: ["package:staging"]
  dependencies: []
  cache: {}
  environment: {
    name: staging
  }
  script:
    - kubectl config set-cluster k8s --server="$KUBE_API_URL" --insecure-skip-tls-verify=true
    - kubectl config set-credentials "$KUBE_DEPLOY_SECRET_NAME" --token="$KUBE_API_TOKEN"
    - kubectl config set-context default --cluster=k8s --user="$KUBE_DEPLOY_SECRET_NAME"
    - kubectl config use-context default
    - helm upgrade power ./chart/power -n staging -f ./chart/power/values-staging.yaml --install
  only:
    - staging

deploy:production:
  stage: deploy
  image: de.icr.io/lgln/kube-tools:latest
  needs: ["package:production"]
  dependencies: []
  cache: {}
  environment: {
    name: production
  }
  script:
    - kubectl config set-cluster k8s --server="$KUBE_API_URL" --insecure-skip-tls-verify=true
    - kubectl config set-credentials "$KUBE_DEPLOY_SECRET_NAME" --token="$KUBE_API_TOKEN"
    - kubectl config set-context default --cluster=k8s --user="$KUBE_DEPLOY_SECRET_NAME"
    - kubectl config use-context default
    - helm upgrade power ./chart/power -n prod -f ./chart/power/values-prod.yaml --install --set replicaCount=1
  only:
    - production
